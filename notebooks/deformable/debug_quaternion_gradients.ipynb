{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import condorgmm\n",
    "import warp as wp\n",
    "wp.init()\n",
    "from condorgmm.utils.common import get_assets_path\n",
    "import condorgmm.data as data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "import warp as wp\n",
    "from condorgmm.warp_gmm.adam import Adam\n",
    "from condorgmm.warp_gmm.state import State\n",
    "import importlib\n",
    "importlib.reload(condorgmm.warp_gmm.adam)\n",
    "condorgmm.rr_init(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H,W = 50,50\n",
    "rgb = np.zeros((H,W,3), dtype=np.float32)\n",
    "depth = np.ones((H,W), dtype=np.float32) * 2.0\n",
    "intrinsics = np.array([100.0, 100.0, W/2.0, H/2.0])\n",
    "camera_pose = np.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0])\n",
    "frame = condorgmm.Frame(rgb=rgb, depth=depth, intrinsics=intrinsics, camera_pose=camera_pose)\n",
    "\n",
    "frame_warp = frame.as_warp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warp as wp\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import rerun as rr\n",
    "\n",
    "\n",
    "condorgmm.rr_init(\"warp\")\n",
    "\n",
    "@wp.func\n",
    "def safe_normalize(quaternion: wp.quat):\n",
    "    return quaternion / wp.sqrt(wp.dot(quaternion, quaternion) + 1e-10)\n",
    "\n",
    "# Define warp kernel for computing loss\n",
    "@wp.kernel\n",
    "def compute_gaussian_loss(\n",
    "    points: wp.array(dtype=wp.vec3, ndim=1),\n",
    "    mean: wp.array(dtype=wp.vec3, ndim=1),\n",
    "    quat_imag: wp.array(dtype=wp.vec3, ndim=1),\n",
    "    quat_real: wp.array(dtype=wp.float32, ndim=1), \n",
    "    log_scales: wp.array(dtype=wp.vec3, ndim=1),\n",
    "    losses: wp.array(dtype=wp.float32, ndim=1),\n",
    "):\n",
    "    idx = wp.tid()\n",
    "    if idx >= points.shape[0]:\n",
    "        return\n",
    "        \n",
    "    # Get point\n",
    "    p = points[idx]\n",
    "    \n",
    "    # Compute difference from mean\n",
    "    diff = p - mean[0]\n",
    "    \n",
    "    # Build covariance from quaternion and scales\n",
    "    quaternion = safe_normalize(wp.quat(quat_imag[0], quat_real[0]))\n",
    "    rot_matrix = wp.quat_to_matrix(quaternion)\n",
    "    scales = wp.vec3(wp.exp(log_scales[0][0]), wp.exp(log_scales[0][1]), wp.exp(log_scales[0][2]))\n",
    "\n",
    "    diagonal_epsilon = wp.vec3(1e-10, 1e-10, 1e-10)  # Increased epsilon\n",
    "    cov = (\n",
    "        rot_matrix\n",
    "        * wp.diag(scales)\n",
    "        * wp.diag(scales)\n",
    "        * wp.transpose(rot_matrix)\n",
    "    ) + wp.diag(diagonal_epsilon)\n",
    "    cov_inv = wp.inverse(cov)\n",
    "    log_det_cov = 2.0 * (wp.log(scales[0]) + wp.log(scales[1]) + wp.log(scales[2]))\n",
    "\n",
    "    logpdf = 0.5 * (\n",
    "        3.0 * wp.log(2.0 * wp.pi)\n",
    "        + log_det_cov\n",
    "        + wp.dot(diff, cov_inv * diff)\n",
    "    )\n",
    "\n",
    "    losses[idx] = logpdf\n",
    "\n",
    "\n",
    "    # scale_matrix = jnp.diag(scales)\n",
    "    # cov = rot_matrix @ jnp.diag(scales**2) @ rot_matrix.T\n",
    "    \n",
    "    # # Compute multivariate Gaussian negative log likelihood\n",
    "    # centered = point - mean\n",
    "    # log_det = jnp.sum(jnp.log(scales)) * 2  # log determinant of covariance\n",
    "    # mahalanobis = jnp.sum(centered * (jnp.linalg.solve(cov, centered)))\n",
    "\n",
    "    # return 0.5 * (3 * jnp.log(2 * jnp.pi) + log_det + mahalanobis)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def score_fn(warp_observed_points, mean, quat_imag, quat_real, log_scales, loss):\n",
    "    wp.launch(kernel=compute_gaussian_loss, dim=(warp_observed_points.shape[0],), inputs=(warp_observed_points, mean, quat_imag, quat_real, log_scales, loss))\n",
    "\n",
    "# The variable 'points' is not defined - should be warp_observed_points\n",
    "warp_observed_points = wp.array(np.array(condorgmm.xyz_from_depth_image(frame.depth, *frame.intrinsics).reshape(-1,3)), dtype=wp.vec3)\n",
    "\n",
    "mean = wp.array(np.array([[0.0, 0.0, 2.2]], dtype=np.float32), dtype=wp.vec3, requires_grad=True)\n",
    "quat_imag = wp.array(np.zeros((1,3), dtype=np.float32), dtype=wp.vec3, requires_grad=True)\n",
    "quat_real = wp.array(np.ones(1, dtype=np.float32), dtype=wp.float32, requires_grad=True)\n",
    "log_scales = wp.array(np.log(0.1 * np.ones((1,3), dtype=np.float32)), dtype=wp.vec3, requires_grad=True)\n",
    "\n",
    "losses = wp.zeros(warp_observed_points.shape[0], dtype=wp.float32, requires_grad=True)\n",
    "print(losses.numpy())\n",
    "score_fn(warp_observed_points, mean, quat_imag, quat_real, log_scales, losses) # Using points instead of warp_observed_points\n",
    "print(losses.numpy())\n",
    "\n",
    "from warp.optim import Adam\n",
    "from condorgmm.warp_gmm.adam import Adam as Adam2\n",
    "\n",
    "# Need to include all parameters that require gradients\n",
    "params_to_optimize = [mean, log_scales]\n",
    "optimizer = Adam2(params_to_optimize, lr=[0.01, 0.01])\n",
    " \n",
    "condorgmm.rr_set_time(0)\n",
    "condorgmm.rr_log_cloud(warp_observed_points.numpy(), channel=\"observed_points\")\n",
    " \n",
    "backward = wp.ones(len(losses), dtype=wp.float32, requires_grad=True)\n",
    "\n",
    "num_steps = 20000\n",
    "pbar = tqdm(range(num_steps))\n",
    "scores = []\n",
    "for step in pbar:\n",
    "    loss = wp.zeros(1, dtype=wp.float32, requires_grad=True)\n",
    "    tape = wp.Tape()\n",
    "    with tape:\n",
    "        # Using points instead of warp_observed_points\n",
    "        score_fn(warp_observed_points, mean, quat_imag, quat_real, log_scales, losses)\n",
    "    tape.backward(grads={losses: backward})\n",
    "    optimizer.step([x.grad for x in params_to_optimize])\n",
    "    logpdf = losses.numpy().sum()\n",
    "    pbar.set_description(f\"Loss: {logpdf}\")\n",
    "    scores.append(logpdf)\n",
    "    tape.zero()\n",
    "    wp.synchronize()\n",
    "    \n",
    "    condorgmm.rr_set_time(step)\n",
    "\n",
    "    rr.log(\n",
    "        \"gmm_warp\",\n",
    "        rr.Ellipsoids3D(\n",
    "            centers=mean.numpy(),\n",
    "            half_sizes=np.exp(log_scales.numpy()),\n",
    "            quaternions=np.concatenate([quat_imag.numpy(), quat_real.numpy()[...,None]], axis=-1),\n",
    "        ),\n",
    "    )\n",
    "plt.plot(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import condorgmm.warp_gmm as warp_gmm\n",
    "import condorgmm.warp_gmm.kernels\n",
    "condorgmm.rr_init(\"gradient_test\")\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "gmm = warp_gmm.gmm_warp.gmm_warp_from_numpy(\n",
    "    spatial_means=np.array([[0.0, 0.0, 2.0]],dtype=np.float32),\n",
    "    rgb_means=np.array([[0.0, 0.0, 0.0]],dtype=np.float32),\n",
    "    log_spatial_scales=np.log(np.array([[0.05, 0.05, 0.05]],dtype=np.float32)),\n",
    "    # quaternions_imaginary=np.array([[0.0, 0.1, -1.0]],dtype=np.float32),\n",
    ")\n",
    "warp_gmm_state = warp_gmm.initialize_state(gmm=gmm, frame=frame)\n",
    "warp_gmm_state.hyperparams.window_half_width = 20\n",
    "warp_gmm_state.hyperparams.outlier_volume = 1e6\n",
    "warp_gmm_state.hyperparams.outlier_probability = 0.001\n",
    "condorgmm.rr_set_time(0)\n",
    "condorgmm.rr_log_frame(frame)\n",
    "\n",
    "warp_gmm.rr_log_gmm_warp(warp_gmm_state.gmm)\n",
    "warp_gmm.warp_gmm_forward(frame_warp, warp_gmm_state)\n",
    "plt.matshow(warp_gmm_state.log_score_image.numpy())\n",
    "\n",
    "warp_gmm_state.gmm.spatial_means.requires_grad = True\n",
    "warp_gmm_state.gmm.log_spatial_scales.requires_grad = True\n",
    "warp_gmm_state.gmm.quaternions_imaginary.requires_grad = True\n",
    "warp_gmm_state.gmm.quaternions_real.requires_grad = True\n",
    "warp_gmm_state.gmm.rgb_means.requires_grad = True\n",
    "print(warp_gmm_state.gmm.spatial_means.numpy())\n",
    "\n",
    "\n",
    "from warp.optim import SGD\n",
    "params_to_optimize = [warp_gmm_state.gmm.log_spatial_scales]\n",
    "optimizer = Adam2(params_to_optimize, lr=[1e-3])\n",
    " \n",
    "condorgmm.rr_set_time(0)\n",
    "condorgmm.rr_log_cloud(warp_observed_points.numpy(), channel=\"observed_points\")\n",
    "\n",
    "num_steps = 20000\n",
    "pbar = tqdm(range(num_steps))\n",
    "scores = []\n",
    "for step in pbar:\n",
    "    tape = wp.Tape()\n",
    "    with tape:\n",
    "        condorgmm.warp_gmm.kernels.warp_gmm_forward(\n",
    "            frame_warp,\n",
    "            warp_gmm_state,\n",
    "        )\n",
    "\n",
    "    tape.backward(grads={warp_gmm_state.log_score_image: warp_gmm_state.backward})\n",
    "    optimizer.step([x.grad for x in params_to_optimize])\n",
    "    loss = warp_gmm_state.log_score_image.numpy().sum()\n",
    "    pbar.set_description(f\"Loss: {loss}\")\n",
    "    scores.append(loss)\n",
    "    tape.zero()\n",
    "    wp.synchronize()\n",
    "\n",
    "    if step % 100 == 0:\n",
    "        condorgmm.rr_set_time(step)\n",
    "        warp_gmm.rr_log_gmm_warp(warp_gmm_state.gmm, size_scalar=1.0)\n",
    "\n",
    "plt.plot(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "# Sample from the GMM\n",
    "num_samples = 1000\n",
    "samples = np.zeros((num_samples, 3), dtype=np.float32)\n",
    "\n",
    "# Get parameters from the GMM\n",
    "spatial_mean = warp_gmm_state.gmm.spatial_means.numpy()[0]\n",
    "spatial_scale = np.exp(warp_gmm_state.gmm.log_spatial_scales.numpy()[0])\n",
    "quat_imag = warp_gmm_state.gmm.quaternions_imaginary.numpy()[0]\n",
    "quat_real = warp_gmm_state.gmm.quaternions_real.numpy()[0]\n",
    "\n",
    "# Construct rotation matrix from quaternion\n",
    "quat = np.concatenate([quat_imag, [quat_real]])\n",
    "rot_matrix = R.from_quat(quat).as_matrix()\n",
    "\n",
    "# Generate samples\n",
    "for i in range(num_samples):\n",
    "    # Sample from standard normal\n",
    "    z = np.random.normal(0, 1, 3).astype(np.float32)\n",
    "    \n",
    "    # Scale, rotate and translate\n",
    "    sample = rot_matrix @ (spatial_scale * z) + spatial_mean\n",
    "    samples[i] = sample\n",
    "\n",
    "# Visualize samples\n",
    "condorgmm.rr_set_time(0)\n",
    "condorgmm.rr_log_cloud(samples, channel=\"gmm_samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit analytically a gaussian to the original points\n",
    "points = condorgmm.xyz_from_depth_image(frame.depth, *frame.intrinsics).reshape(-1,3)\n",
    "mean = np.mean(points, axis=0)\n",
    "cov = np.cov(points, rowvar=False)\n",
    "\n",
    "# Draw samples from the gaussian\n",
    "samples = np.random.multivariate_normal(mean, cov, size=num_samples)\n",
    "condorgmm.rr_log_cloud(samples, channel=\"gmm_samples_analytical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import condorgmm.warp_gmm as warp_gmm\n",
    "import condorgmm.warp_gmm.kernels\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "condorgmm.rr_set_time(0)\n",
    "condorgmm.rr_log_frame(frame)\n",
    "\n",
    "gmm = warp_gmm.gmm_warp.gmm_warp_from_numpy(\n",
    "    spatial_means=np.array([[0.0, 0.0, 1.0]],dtype=np.float32),\n",
    "    rgb_means=np.array([[0.0, 0.0, 0.0]],dtype=np.float32),\n",
    ")\n",
    "warp_gmm_state = warp_gmm.initialize_state(gmm=gmm, frame=frame)\n",
    "warp_gmm_state.hyperparams.window_half_width = 20\n",
    "warp_gmm_state.hyperparams.outlier_volume = 1e6\n",
    "warp_gmm.rr_log_gmm_warp(warp_gmm_state.gmm)\n",
    "\n",
    "\n",
    "for _ in range(5):\n",
    "    warp_gmm.warp_gmm_EM_step(frame_warp, warp_gmm_state)\n",
    "warp_gmm.rr_log_gmm_warp(warp_gmm_state.gmm)\n",
    "warp_gmm.warp_gmm_forward(frame_warp, warp_gmm_state)\n",
    "\n",
    "plt.matshow(warp_gmm_state.log_score_image.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import condorgmm.warp_gmm as warp_gmm\n",
    "import condorgmm.warp_gmm.kernels\n",
    "condorgmm.rr_init(\"gradient_test\")\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "gmm = warp_gmm.gmm_warp.gmm_warp_from_numpy(\n",
    "    spatial_means=np.array([[0.0, 0.0, 2.1]],dtype=np.float32),\n",
    "    rgb_means=np.array([[0.0, 0.0, 0.0]],dtype=np.float32),\n",
    "    log_spatial_scales=np.log(np.array([[0.1, 0.1, 0.1]],dtype=np.float32)),\n",
    "    # quaternions_imaginary=np.array([[0.0, 0.1, -1.0]],dtype=np.float32),\n",
    ")\n",
    "warp_gmm_state = warp_gmm.initialize_state(gmm=gmm, frame=frame)\n",
    "warp_gmm_state.hyperparams.window_half_width = 20\n",
    "warp_gmm_state.hyperparams.outlier_volume = 1e6\n",
    "warp_gmm_state.hyperparams.outlier_probability = 0.0\n",
    "condorgmm.rr_set_time(0)\n",
    "condorgmm.rr_log_frame(frame)\n",
    "\n",
    "warp_gmm.rr_log_gmm_warp(warp_gmm_state.gmm)\n",
    "warp_gmm.warp_gmm_forward(frame_warp, warp_gmm_state)\n",
    "plt.matshow(warp_gmm_state.log_score_image.numpy())\n",
    "\n",
    "warp_gmm_state.gmm.spatial_means.requires_grad = True\n",
    "warp_gmm_state.gmm.log_spatial_scales.requires_grad = True\n",
    "warp_gmm_state.gmm.quaternions_imaginary.requires_grad = True\n",
    "warp_gmm_state.gmm.quaternions_real.requires_grad = True\n",
    "warp_gmm_state.gmm.rgb_means.requires_grad = True\n",
    "params_to_optimize = [warp_gmm_state.gmm.spatial_means, warp_gmm_state.gmm.log_spatial_scales]\n",
    "optimizer = Adam(params_to_optimize, lr=[1e-10, 1e-2])\n",
    "print(warp_gmm_state.gmm.spatial_means.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_timesteps = 1000\n",
    "pbar = tqdm(range(num_timesteps)) if tqdm else range(num_timesteps)\n",
    "scores = []\n",
    "for step in pbar:\n",
    "    tape = wp.Tape()\n",
    "    with tape:\n",
    "        condorgmm.warp_gmm.kernels.warp_gmm_forward(\n",
    "            frame_warp,\n",
    "            warp_gmm_state,\n",
    "        )\n",
    "\n",
    "    tape.backward(grads={warp_gmm_state.log_score_image: warp_gmm_state.backward})\n",
    "    # for x in params_to_optimize:\n",
    "    #     print(x.grad.numpy(), x.grad.numpy())\n",
    "\n",
    "    optimizer.step([x.grad for x in params_to_optimize])\n",
    "\n",
    "    # quaternions = np.concatenate([warp_gmm_state.gmm.quaternions_imaginary.numpy(), warp_gmm_state.gmm.quaternions_real.numpy()[...,None]], axis=-1)\n",
    "    # quaternions = quaternions / np.linalg.norm(quaternions, axis=-1, keepdims=True)\n",
    "    # warp_gmm_state.gmm.quaternions_imaginary = wp.array(quaternions[:, :3],requires_grad=True, dtype=wp.vec3)\n",
    "    # warp_gmm_state.gmm.quaternions_real = wp.array(quaternions[:, 3],requires_grad=True, dtype=wp.float32)\n",
    "\n",
    "    warp_gmm.warp_gmm_forward(frame_warp, warp_gmm_state)\n",
    "    score = warp_gmm_state.log_score_image.numpy().sum()\n",
    "    scores.append(score)\n",
    "    pbar.set_description(f\"Log score: {score}\")\n",
    "\n",
    "    condorgmm.rr_set_time(step)\n",
    "    warp_gmm.rr_log_gmm_warp(warp_gmm_state.gmm)\n",
    "\n",
    "warp_gmm.warp_gmm_forward(frame_warp, warp_gmm_state)\n",
    "plt.matshow(warp_gmm_state.log_score_image.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import grad, jit\n",
    "import numpy as np\n",
    "import rerun as rr\n",
    "\n",
    "condorgmm.rr_init(\"jax\")\n",
    "\n",
    "# Generate some random 3D point cloud data\n",
    "key = jax.random.PRNGKey(0)\n",
    "observed_points = jnp.array(condorgmm.xyz_from_depth_image(frame.depth, *frame.intrinsics).reshape(-1,3)) \n",
    "\n",
    "condorgmm.rr_log_cloud(observed_points, channel=\"observed_points\")\n",
    "# n_points = 1000\n",
    "# observed_points = jax.random.normal(key, (n_points, 3)) * 0.1 + jnp.array([1.0, 2.0, -0.5])\n",
    "\n",
    "\n",
    "# Initialize parameters\n",
    "def init_params():\n",
    "    return {\n",
    "        'log_scales': jnp.log(jnp.ones(3) * 0.1),  # log of scale parameters\n",
    "        'quat': jnp.array([0.0, 0.0, 0.0, 1.0]),  # quaternion [x,y,z,w]\n",
    "        'mean': jnp.array([0., 0., 2.1])  # mean position\n",
    "    }\n",
    "\n",
    "# Quaternion rotation\n",
    "def quat_rotate(q, v):\n",
    "    qx, qy, qz, qw = q\n",
    "    return 2.0 * (\n",
    "        v * (qw * qw - 0.5) +\n",
    "        jnp.cross(jnp.array([qx, qy, qz]), v) * qw +\n",
    "        jnp.array([qx, qy, qz]) * jnp.dot(jnp.array([qx, qy, qz]), v)\n",
    "    )\n",
    "\n",
    "# Negative log likelihood for a single point\n",
    "def point_nll(params, point):\n",
    "    # Extract parameters\n",
    "    scales = jnp.exp(params['log_scales'])\n",
    "    quat = params['quat'] / jnp.linalg.norm(params['quat'])  # normalize quaternion\n",
    "    mean = params['mean']\n",
    "\n",
    "    # Construct covariance matrix using rotation and scales\n",
    "    rot_matrix = jnp.array([\n",
    "        [1 - 2*(quat[1]**2 + quat[2]**2), 2*(quat[0]*quat[1] - quat[2]*quat[3]), 2*(quat[0]*quat[2] + quat[1]*quat[3])],\n",
    "        [2*(quat[0]*quat[1] + quat[2]*quat[3]), 1 - 2*(quat[0]**2 + quat[2]**2), 2*(quat[1]*quat[2] - quat[0]*quat[3])],\n",
    "        [2*(quat[0]*quat[2] - quat[1]*quat[3]), 2*(quat[1]*quat[2] + quat[0]*quat[3]), 1 - 2*(quat[0]**2 + quat[1]**2)]\n",
    "    ])\n",
    "    \n",
    "    scale_matrix = jnp.diag(scales)\n",
    "    cov = rot_matrix @ jnp.diag(scales**2) @ rot_matrix.T\n",
    "    \n",
    "    # Compute multivariate Gaussian negative log likelihood\n",
    "    centered = point - mean\n",
    "    log_det = jnp.sum(jnp.log(scales)) * 2  # log determinant of covariance\n",
    "    mahalanobis = jnp.sum(centered * (jnp.linalg.solve(cov, centered)))\n",
    "\n",
    "    return 0.5 * (3 * jnp.log(2 * jnp.pi) + log_det + mahalanobis)\n",
    "\n",
    "# Total loss for all points\n",
    "@jit\n",
    "def total_loss(params, points):\n",
    "    return jnp.mean(jax.vmap(lambda p: point_nll(params, p))(points))\n",
    "\n",
    "# Gradient function\n",
    "grad_fn = jit(grad(total_loss))\n",
    "\n",
    "points = observed_points\n",
    "\n",
    "params = init_params()\n",
    "\n",
    "# log\n",
    "rr.log(\n",
    "    \"jax_gmm_initial\",\n",
    "    rr.Ellipsoids3D(\n",
    "        centers=jnp.array([params['mean']]),\n",
    "        half_sizes=jnp.exp(params['log_scales']),\n",
    "        quaternions=params['quat'],\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Initialize Adam optimizer state\n",
    "from jax.example_libraries.optimizers import adam\n",
    "opt_init, opt_update, get_params = adam(step_size=0.01)\n",
    "opt_state = opt_init(params)\n",
    "\n",
    "@jax.jit\n",
    "def update_params(opt_state, points):\n",
    "    grads = grad_fn(get_params(opt_state), points)\n",
    "    opt_state = opt_update(i, grads, opt_state)\n",
    "    return opt_state\n",
    "\n",
    "num_steps = 5000\n",
    "pbar = tqdm(range(num_steps))\n",
    "scores = []\n",
    "for i in pbar:\n",
    "\n",
    "    opt_state = update_params(opt_state, points)   \n",
    "    params = get_params(opt_state)\n",
    "    loss = total_loss(params, points)\n",
    "    scores.append(loss)\n",
    "    pbar.set_description(f\"Loss: {loss:.4f}\")\n",
    "    condorgmm.rr_set_time(i)\n",
    "    # log\n",
    "    rr.log(\n",
    "        \"jax_gmm_fitted\",\n",
    "        rr.Ellipsoids3D(\n",
    "            centers=jnp.array([params['mean']]),\n",
    "            half_sizes=jnp.exp(params['log_scales']),\n",
    "            quaternions=params['quat'],\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nFitted parameters:\")\n",
    "print(\"Scales:\", jnp.exp(params['log_scales']))\n",
    "print(\"Quaternion:\", params['quat'])\n",
    "print(\"Mean:\", params['mean'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# log\n",
    "rr.log(\n",
    "    \"jax_gmm_fitted\",\n",
    "    rr.Ellipsoids3D(\n",
    "        centers=jnp.array([params['mean']]),\n",
    "        half_sizes=jnp.exp(params['log_scales']),\n",
    "        quaternions=params['quat'],\n",
    "    ),\n",
    ")\n",
    "\n",
    "plt.plot(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate([quat_imag.numpy(), quat_real.numpy()[...,None]], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warp_observed_points.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
