{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import condorgmm\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import condorgmm.eval.metrics\n",
    "from condorgmm.utils.common.pose import Pose\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import pandas as pd\n",
    "\n",
    "results_directory = \"/home/nishadgothoskar/condorgmm/results/object_pose_tracking_ycbv_test_em__2025-03-05-02-11-29\"\n",
    "results_files = glob.glob(results_directory + \"/*.pkl\")\n",
    "results_dfs = [pd.read_pickle(f) for f in results_files]\n",
    "concatenated_df = pd.concat(results_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "se3_results_dir = condorgmm.get_root_path() / \"assets\" / \"se3_results\"\n",
    "video = condorgmm.data.YCBTestVideo(48)\n",
    "print(video.SCENE_NAMES)\n",
    "\n",
    "object_names = video.YCB_MODEL_NAMES\n",
    "\n",
    "all_results = []\n",
    "\n",
    "max_T = 400\n",
    "\n",
    "se3_pose_predictions = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"scene\",\n",
    "        \"method\",\n",
    "        \"object\",\n",
    "        \"timestep\",\n",
    "        \"predicted\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Iterate through each object directory\n",
    "for object_name in object_names:\n",
    "    object_dir = se3_results_dir / object_name\n",
    "    print(object_name)    \n",
    "    # Iterate through each scene directory\n",
    "    mid_dir = list(object_dir.glob(\"*\"))\n",
    "    scene_dirs = list(mid_dir[0].glob(\"*\"))\n",
    "    \n",
    "    # Extract scene number from directory name (seqXX)\n",
    "\n",
    "    predicted_poses = []\n",
    "    gt_poses = []\n",
    "    for scene_dir in scene_dirs:\n",
    "        scene_num = int(scene_dir.name.split('seq')[-1])\n",
    "        print(scene_num)\n",
    "\n",
    "        video = condorgmm.data.YCBTestVideo(scene_num)\n",
    "        object_id = video.YCB_MODEL_NAMES.index(object_name)\n",
    "        object_index = list(video[0].object_ids).index(object_id)\n",
    "\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            predicted_poses = list(\n",
    "                executor.map(\n",
    "                    lambda timestep: condorgmm.Pose.from_matrix(np.loadtxt(scene_dir / f\"{str(timestep).zfill(7)}.txt\")).posquat,\n",
    "                    range(max_T),\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        new_rows = pd.DataFrame({'scene': scene_num, 'method': 'SE3-Tracknet', 'object': object_name, 'timestep': range(max_T), 'predicted': predicted_poses})\n",
    "        se3_pose_predictions = pd.concat([se3_pose_predictions, new_rows], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_of_concatenated_df = concatenated_df.copy()\n",
    "copy_of_concatenated_df = copy_of_concatenated_df[copy_of_concatenated_df[\"metric\"] == \"ADD\"]\n",
    "copy_of_concatenated_df = copy_of_concatenated_df[[\"scene\", \"object\", \"timestep\", \"gt\"]]\n",
    "se3_pose_predictions_with_gt = se3_pose_predictions.merge(copy_of_concatenated_df, on=[\"scene\", \"object\", \"timestep\"], how=\"right\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se3_results_df = condorgmm.eval.metrics.create_empty_results_dataframe()\n",
    "\n",
    "object_names = condorgmm.data.YCBTestVideo.YCB_MODEL_NAMES\n",
    "for scene_name in video.SCENE_NAMES:\n",
    "    print(scene_name)\n",
    "    video = condorgmm.data.YCBTestVideo(scene_name)\n",
    "    \n",
    "\n",
    "    object_ids = video[0].object_ids\n",
    "    for object_id in object_ids:\n",
    "        object_name = video.YCB_MODEL_NAMES[object_id]\n",
    "        partial_df = se3_pose_predictions_with_gt[se3_pose_predictions_with_gt[\"scene\"] == scene_name]\n",
    "        partial_df = partial_df[partial_df[\"object\"] == object_name]\n",
    "\n",
    "        predicted_poses = partial_df[\"predicted\"].tolist()\n",
    "        gt_poses = partial_df[\"gt\"].tolist()\n",
    "\n",
    "        vertices = video.get_object_mesh_from_id(\n",
    "            object_id\n",
    "        ).vertices\n",
    "\n",
    "        condorgmm.eval.metrics.add_object_tracking_metrics_to_results_dataframe(\n",
    "            se3_results_df,\n",
    "            scene_name,\n",
    "            \"SE3-Tracknet\",\n",
    "            object_name,\n",
    "            [condorgmm.Pose(pose) for pose in predicted_poses],\n",
    "            [condorgmm.Pose(pose) for pose in gt_poses],\n",
    "            vertices,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se3_results_df\n",
    "\n",
    "# Save metrics to file.\n",
    "se3_results_df.to_pickle(\n",
    "    condorgmm.get_root_path() / \"assets\" / \"se3_results\" / \"se3_results_df_400.pkl\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_files = glob.glob(results_directory + \"/*.pkl\")\n",
    "results_dfs = [pd.read_pickle(f) for f in results_files]\n",
    "concatenated_df = pd.concat(results_dfs)\n",
    "\n",
    "video = condorgmm.data.YCBTestVideo(48)\n",
    "\n",
    "results_df = results_dfs[0]\n",
    "scene, object_name = results_df.iloc[0][\"scene\"], results_df.iloc[0][\"object\"]\n",
    "max_T = results_df[\"timestep\"].max()\n",
    "\n",
    "\n",
    "## Load FoundationPose results\n",
    "ycb_dir = video.ycb_dir\n",
    "\n",
    "all_foundation_pose_results_df = []\n",
    "fp_loader = condorgmm.eval.fp_loader.YCBVTrackingResultLoader(\n",
    "    frame_rate=1, split=ycb_dir.name\n",
    ")\n",
    "\n",
    "for scene in video.SCENE_NAMES:\n",
    "    print(\"Scene: \", scene)\n",
    "    video = condorgmm.data.YCBTestVideo(scene)\n",
    "\n",
    "    df = fp_loader.get_dataframe(scene)\n",
    "    df = df[df[\"timestep\"] < max_T + 1]\n",
    "    all_foundation_pose_results_df.append(df)\n",
    "\n",
    "all_foundation_pose_results_df_concatenated = pd.concat(\n",
    "    all_foundation_pose_results_df\n",
    ")\n",
    "\n",
    "all_se3_results_loaded = pd.read_pickle(condorgmm.get_root_path() / \"assets\" / \"se3_results\" / \"se3_results_df_400.pkl\")\n",
    "\n",
    "assert len(all_foundation_pose_results_df_concatenated) == len(concatenated_df) == len(all_se3_results_loaded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate all results\n",
    "all_results_df = pd.concat(\n",
    "    [concatenated_df, all_foundation_pose_results_df_concatenated, all_se3_results_loaded]\n",
    ")\n",
    "\n",
    "auc_results = all_results_df.groupby([\"metric\", \"object\", \"method\"])[\"value\"].apply(\n",
    "    condorgmm.eval.metrics.compute_auc\n",
    ")\n",
    "print(auc_results)\n",
    "\n",
    "model_names = condorgmm.data.YCBTestVideo.YCB_MODEL_NAMES\n",
    "methods = [\"SE3-Tracknet\", \"FoundationPose\", \"condorgmm\"]\n",
    "\n",
    "table_string = \"\"\"\"\"\"\n",
    "for object_name in model_names:\n",
    "    add_results = [\n",
    "        auc_results[\"ADD\"][object_name][method] * 100.0 for method in methods\n",
    "    ]\n",
    "    adds_results = [\n",
    "        auc_results[\"ADD-S\"][object_name][method] * 100.0 for method in methods\n",
    "    ]\n",
    "\n",
    "    # Get indices sorted by score (descending)\n",
    "    add_sorted_indices = np.argsort(add_results)[::-1]\n",
    "    adds_sorted_indices = np.argsort(adds_results)[::-1]\n",
    "\n",
    "    object_name_mod = object_name.replace(r\"_\", r\"\\_\")\n",
    "    table_string += rf\"{object_name_mod}\"\n",
    "\n",
    "    for i in range(len(methods)):\n",
    "        # Color coding for ADD\n",
    "        if i == add_sorted_indices[0]:\n",
    "            table_string += (\n",
    "                r\" & \\cellcolor{green}{\"\n",
    "                + rf\"\\textbf{{{add_results[i]:.1f}}}\"\n",
    "                + r\"}\"\n",
    "            )\n",
    "        elif i == add_sorted_indices[1]:\n",
    "            table_string += (\n",
    "                r\" & \\cellcolor{yellow}{\" + rf\"{add_results[i]:.1f}\" + r\"}\"\n",
    "            )\n",
    "        else:\n",
    "            table_string += (\n",
    "                r\" & \\cellcolor{orange}{\" + rf\"{add_results[i]:.1f}\" + r\"}\"\n",
    "            )\n",
    "\n",
    "        # Color coding for ADD-S\n",
    "        if i == adds_sorted_indices[0]:\n",
    "            table_string += (\n",
    "                r\" & \\cellcolor{green}{\"\n",
    "                + rf\"\\textbf{{{adds_results[i]:.1f}}}\"\n",
    "                + r\"}\"\n",
    "            )\n",
    "        elif i == adds_sorted_indices[1]:\n",
    "            table_string += (\n",
    "                r\" & \\cellcolor{yellow}{\" + rf\"{adds_results[i]:.1f}\" + r\"}\"\n",
    "            )\n",
    "        else:\n",
    "            table_string += (\n",
    "                r\" & \\cellcolor{orange}{\" + rf\"{adds_results[i]:.1f}\" + r\"}\"\n",
    "            )\n",
    "\n",
    "    table_string += r\"\\\\\" + \"\\n\"\n",
    "\n",
    "table_string += r\"\\hline\" + \"\\n\"\n",
    "\n",
    "auc_results_full = all_results_df.groupby([\"metric\", \"method\"])[\"value\"].apply(\n",
    "    condorgmm.eval.metrics.compute_auc\n",
    ")\n",
    "print(auc_results_full)\n",
    "\n",
    "add_results = [auc_results_full[\"ADD\"][method] * 100.0 for method in methods]\n",
    "adds_results = [auc_results_full[\"ADD-S\"][method] * 100.0 for method in methods]\n",
    "\n",
    "# Get indices sorted by score (descending)\n",
    "add_sorted_indices = np.argsort(add_results)[::-1]\n",
    "adds_sorted_indices = np.argsort(adds_results)[::-1]\n",
    "\n",
    "table_string += r\"All Frames\"\n",
    "\n",
    "for i in range(len(methods)):\n",
    "    # Color coding for ADD\n",
    "    if i == add_sorted_indices[0]:\n",
    "        table_string += (\n",
    "            r\" & \\cellcolor{green}{\" + rf\"\\textbf{{{add_results[i]:.1f}}}\" + r\"}\"\n",
    "        )\n",
    "    elif i == add_sorted_indices[1]:\n",
    "        table_string += r\" & \\cellcolor{yellow}{\" + rf\"{add_results[i]:.1f}\" + r\"}\"\n",
    "    else:\n",
    "        table_string += r\" & \\cellcolor{orange}{\" + rf\"{add_results[i]:.1f}\" + r\"}\"\n",
    "\n",
    "    # Color coding for ADD-S\n",
    "    if i == adds_sorted_indices[0]:\n",
    "        table_string += (\n",
    "            r\" & \\cellcolor{green}{\" + rf\"\\textbf{{{adds_results[i]:.1f}}}\" + r\"}\"\n",
    "        )\n",
    "    elif i == adds_sorted_indices[1]:\n",
    "        table_string += r\" & \\cellcolor{yellow}{\" + rf\"{adds_results[i]:.1f}\" + r\"}\"\n",
    "    else:\n",
    "        table_string += r\" & \\cellcolor{orange}{\" + rf\"{adds_results[i]:.1f}\" + r\"}\"\n",
    "\n",
    "table_string += r\"\\\\\" + \"\\n\"\n",
    "\n",
    "full_table_string = (\n",
    "    r\"\"\"\n",
    "\\begin{table}[]\n",
    "\\centering\n",
    "\\caption{\\textbf{Object Pose Tracking on YCB-Video Dataset}} \n",
    "\\begin{tabular}{lcccccc}\n",
    "\\toprule\n",
    "\\textbf{Method}& \\multicolumn{2}{c}{SE3-Tracknet} &  \\multicolumn{2}{c}{FoundationPose} & \\multicolumn{2}{c}{condorgmm} \\\\\n",
    "\\midrule\n",
    "\\textbf{Object} & ADD & ADD-S & ADD & ADD-S & ADD & ADD-S \\\\\n",
    "\\midrule\n",
    "\"\"\"\n",
    "    + table_string\n",
    "    + r\"\\hline FPS & 90.1 & 30.0 & 40.1 \\bottomrule \\end{tabular} \\end{table}\"\n",
    ")\n",
    "\n",
    "tex_dir = condorgmm.get_root_path() / \"condorgmm_tex\"\n",
    "with open(tex_dir / \"ycbv_pose_tracking_table.tex\", \"w\") as f:\n",
    "    f.write(full_table_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_se3_results_loaded[[\"scene\", \"object\", \"timestep\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_df[concatenated_df[\"object\"] == \"002_master_chef_can\"][\"scene\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "22000*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
