{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import genjax\n",
    "genjax.pretty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load a video ##\n",
    "\n",
    "import condorgmm\n",
    "import condorgmm.data as data\n",
    "\n",
    "video = (\n",
    "    data.YCBVVideo.training_scene(2)\n",
    "    # .downscale(CFG.downscale)\n",
    "    .downscale(16)\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(video[1].rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from condorgmm.condor.interface.camera_tracking import initialize, update\n",
    "\n",
    "frame=video[0]\n",
    "    \n",
    "camera_pose_world_frame=condorgmm.Pose(video[0].camera_pose)\n",
    "gmm0, ccts0 = initialize(\n",
    "    frame,\n",
    "    CFG.n_gaussians,\n",
    "    camera_pose_world_frame,\n",
    "    tile_size_x=CFG.tile_size_x,\n",
    "    tile_size_y=CFG.tile_size_y,\n",
    "    max_n_gaussians_per_tile=CFG.max_n_gaussians_per_tile,\n",
    ")\n",
    "hypers = ccts0.hypers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "from condorgmm.condor.types import CondorGMMState\n",
    "from condorgmm.condor.tiling import GridTiling, GridTilingConfig\n",
    "import jax.numpy as jnp\n",
    "\n",
    "def check_datapoint_in_tiling(\n",
    "    st: CondorGMMState,\n",
    "    idx: int\n",
    "):\n",
    "    tiling: GridTiling = st.matter.tiling\n",
    "    assoc = st.datapoints.value.gaussian_idx[idx]\n",
    "    gaussian_tile = tiling.gaussian_to_tile[assoc]\n",
    "    dp_tile_y, dp_tile_x = tiling.config.datapoint_index_to_tile_index(idx)\n",
    "    dp_tile = jnp.array([dp_tile_y, dp_tile_x])\n",
    "    return jnp.all(jnp.abs(gaussian_tile - dp_tile) < 2)\n",
    "\n",
    "st = ccts0.state\n",
    "valid = jax.vmap(check_datapoint_in_tiling, in_axes=(None, 0))(\n",
    "    st, jnp.arange(len(st.datapoints.value))\n",
    ")\n",
    "jnp.all(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rerun as rr\n",
    "from condorgmm.condor.rerun import log_state\n",
    "\n",
    "# condorgmm.rr_init(\"step_inference_04\")\n",
    "\n",
    "# rr.set_time_sequence(\"inference\", -1)\n",
    "# log_state(ccts0.state, hypers)\n",
    "# rr.log(\"depth_img/observation\", rr.DepthImage(video[0].depth))\n",
    "# rr.log(\"depth_img/inferred\", rr.DepthImage(ccts0.state.datapoints.value.xyz[..., 2].reshape(frame.depth.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame1 = video[100]\n",
    "# import jax.numpy as jnp\n",
    "\n",
    "# gmm1, ccts1, meta = update(\n",
    "#     frame=frame1,\n",
    "#     camera_pose_world_frame=condorgmm.Pose(frame1.camera_pose),\n",
    "#     prev_state=ccts0.replace(hypers=ccts0.hypers.replace(crp_alpha_for_new_gaussian_in_step_model=jnp.array(0.1, dtype=float))),\n",
    "#     n_sweeps_first_pass=1,\n",
    "#     n_sweeps_second_pass=4,\n",
    "#     run_second_pass=True,\n",
    "#     log=True\n",
    "# )\n",
    "# # 1, 2 is probably enough.  possibly even 1, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idxs = ccts1.state.matter.tiling.tile_to_gaussians\n",
    "# jnp.sum(\n",
    "#     # jnp.where(ccts1.state.gaussian_has_assoc_mask[idxs], idxs, -1) != -1,\n",
    "#     idxs > 0,\n",
    "#     axis=-1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idxs = ccts1.state.matter.tiling.tile_to_gaussians\n",
    "# jnp.sum(\n",
    "#     jnp.where(ccts1.state.gaussian_has_assoc_mask[idxs], idxs, -1) != -1,\n",
    "#     axis=-1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# condorgmm.rr_init(\"step_inference_debug_00\")\n",
    "\n",
    "# rr.set_time_sequence(\"inference_step\", -1)\n",
    "# log_state(ccts0.state, hypers)\n",
    "# rr.log(\"depth_img/observation\", rr.DepthImage(video[0].depth))\n",
    "# rr.log(\"depth_img/inferred\", rr.DepthImage(ccts0.state.datapoints.value.xyz[..., 2].reshape(frame.depth.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from condorgmm.condor.rerun import log_state\n",
    "# import rerun as rr\n",
    "# frame = frame1\n",
    "# for (i, label) in enumerate(meta.visited_states.all_labels):\n",
    "#     rr.set_time_sequence(\"inference_step\", i)\n",
    "#     log_state(meta.visited_states.states[i], hypers)\n",
    "#     rr.log(\"inference_move\", rr.TextDocument(label))\n",
    "#     rr.log(\"depth_img/observation\", rr.DepthImage(frame.depth))\n",
    "#     rr.log(\"depth_img/inferred\", rr.DepthImage(meta.visited_states.states[i].datapoints.value.xyz[..., 2].reshape(frame.depth.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condorgmm.rr_init(\"step_run_01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import jax.numpy as jnp\n",
    "\n",
    "def _f(x):\n",
    "    return jnp.array(x, dtype=jnp.float32)\n",
    "# ccts = ccts0.replace(\n",
    "#     hypers=hypers.replace(\n",
    "#         alpha_multiplier_for_evolved_gaussian=_f(5.0),\n",
    "#         crp_alpha_for_new_gaussian_in_step_model=_f(5.0),\n",
    "#     )\n",
    "# )\n",
    "ccts = ccts0\n",
    "\n",
    "for i in tqdm(range(1000)):\n",
    "    if i % 10 == 0:\n",
    "        _, ccts = update(\n",
    "            frame=video[i],\n",
    "            camera_pose_world_frame=condorgmm.Pose(video[i].camera_pose),\n",
    "            prev_state=ccts,\n",
    "            n_sweeps_first_pass=CFG.n_steps_phase1,\n",
    "            n_sweeps_second_pass=CFG.n_steps_phase2,\n",
    "            run_second_pass=True\n",
    "        )\n",
    "    if i % 140 == 0:\n",
    "        rr.set_time_sequence(\"inference\", i+1)\n",
    "        log_state(ccts.state, hypers)\n",
    "        rr.log(\"depth_img/observation\", rr.DepthImage(video[i].depth))\n",
    "        rr.log(\"depth_img/inferred\", rr.DepthImage(ccts.state.datapoints.value.xyz[..., 2].reshape(frame.depth.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
