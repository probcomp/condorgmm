{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import condorgmm\n",
    "import condorgmm.data\n",
    "import matplotlib.pyplot as plt\n",
    "import warp as wp\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import condorgmm.warp_gmm as warp_gmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "condorgmm.rr_init(\"low_frame_rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = 48\n",
    "video = condorgmm.data.YCBTestVideo(scene)\n",
    "frame = video[0]\n",
    "\n",
    "ycb_dir = video.ycb_dir\n",
    "\n",
    "import trimesh\n",
    "@staticmethod\n",
    "def vertices_and_colors_from_obj_file(path, scale=1.0):\n",
    "    trimesh_mesh = trimesh.load_mesh(path, process=False, validate=False)\n",
    "    vertices = np.array(trimesh_mesh.vertices)\n",
    "    if not isinstance(trimesh_mesh.visual, trimesh.visual.color.ColorVisuals):\n",
    "        vertex_colors = (\n",
    "            np.array(trimesh_mesh.visual.to_color().vertex_colors)[..., :3] / 255.0\n",
    "        )\n",
    "    else:\n",
    "        vertex_colors = (\n",
    "            np.array(trimesh_mesh.visual.vertex_colors)[..., :3] / 255.0\n",
    "        )\n",
    "    return vertices * scale, vertex_colors\n",
    "\n",
    "import os\n",
    "meshes = [\n",
    "    vertices_and_colors_from_obj_file(\n",
    "        os.path.join(ycb_dir, f'../models/obj_{f\"{id + 1}\".rjust(6, \"0\")}.ply'), scale=0.001\n",
    "    )\n",
    "    for id in video[0].object_ids\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warp 1.6.0 initialized:\n",
      "   CUDA Toolkit 12.8, Driver 12.4\n",
      "   Devices:\n",
      "     \"cpu\"      : \"x86_64\"\n",
      "     \"cuda:0\"   : \"NVIDIA L4\" (22 GiB, sm_89, mempool enabled)\n",
      "   Kernel cache:\n",
      "     /home/nishadgothoskar/.cache/warp/1.6.0\n"
     ]
    }
   ],
   "source": [
    "num_poses = 20000\n",
    "\n",
    "c2f_schedule_params = (\n",
    "    (0.04, 1000.0),\n",
    "    (0.02, 1500.0),\n",
    "    (0.01, 3000.0),\n",
    "    (0.005, 4000.0),\n",
    ")\n",
    "c2f_schedule = []\n",
    "\n",
    "for c2f_step in c2f_schedule_params:\n",
    "    sigma, kappa = c2f_step\n",
    "    position_deltas = np.random.normal(0.0, sigma, size=(num_poses, 3))\n",
    "    quaternion_deltas = scipy.stats.vonmises_fisher(\n",
    "        mu=np.array([0, 0, 0, 1]),\n",
    "        kappa=kappa,\n",
    "    ).rvs(num_poses)\n",
    "\n",
    "    include_identity = True\n",
    "    if include_identity:\n",
    "        position_deltas[0, :] = 0.0\n",
    "        quaternion_deltas[0, :] = np.array([0, 0, 0, 1])\n",
    "\n",
    "    pose_deltas = wp.array(\n",
    "        np.hstack((position_deltas, quaternion_deltas)), dtype=wp.transform\n",
    "    )\n",
    "    c2f_schedule.append(pose_deltas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = range(0,len(video), 50)\n",
    "for T in timesteps:\n",
    "    condorgmm.rr_set_time(T)\n",
    "    condorgmm.rr_log_frame(video[T])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.05233599 -0.0130313   0.8615899   0.0024441   0.69188577  0.26218858\n",
      " -0.6727148 ]\n"
     ]
    }
   ],
   "source": [
    "from condorgmm.warp_gmm.enumeration_kernels import inference_step\n",
    "importlib.reload(warp_gmm.enumeration_kernels)\n",
    "from condorgmm.warp_gmm.enumeration_kernels import inference_step\n",
    "condorgmm.rr_init(\"low_frame_rate\")\n",
    "frame = video[0]\n",
    "\n",
    "object_index = 3\n",
    "current_object_index = object_index\n",
    "spatial_means = meshes[object_index][0]\n",
    "rgb_means = meshes[object_index][1] * 255.0\n",
    "initial_object_pose_in_camera_frame = (condorgmm.Pose(frame.camera_pose).inv() @ condorgmm.Pose(frame.object_poses[object_index]))\n",
    "\n",
    "transformed_points = initial_object_pose_in_camera_frame.apply(spatial_means)\n",
    "proj_pixel_coords = (transformed_points[:, :2] / transformed_points[:, 2:3]) * np.array([frame.intrinsics[0], frame.intrinsics[1]]) + np.array([frame.intrinsics[2], frame.intrinsics[3]])\n",
    "rounded_pixel_coordinates = np.floor(proj_pixel_coords).astype(np.int32)\n",
    "associated_rgb = frame.rgb[rounded_pixel_coordinates[:, 1], rounded_pixel_coordinates[:, 0]]\n",
    "associated_depth = frame.depth[rounded_pixel_coordinates[:, 1], rounded_pixel_coordinates[:, 0]]\n",
    "matching = np.abs(associated_depth - transformed_points[:, 2]) < 0.01\n",
    "\n",
    "# spatial_means = spatial_means[matching]\n",
    "rgb_means[matching,:] = associated_rgb[matching,:]\n",
    "\n",
    "# mask = frame.masks[object_index]\n",
    "# spatial_means = condorgmm.xyz_from_depth_image(frame.depth, *frame.intrinsics)[mask]\n",
    "# rgb_means = frame.rgb[mask]\n",
    "# spatial_means = initial_object_pose_in_camera_frame.inv().apply(spatial_means)\n",
    "\n",
    "# indices = np.random.choice(\n",
    "#     len(spatial_means),\n",
    "#     (min(len(spatial_means), 5000),),\n",
    "#     replace=False,\n",
    "# )\n",
    "# spatial_means = spatial_means[indices]\n",
    "# rgb_means = rgb_means[indices]\n",
    "\n",
    "gmm = warp_gmm.gmm_warp_from_numpy(\n",
    "    spatial_means.astype(np.float32),\n",
    "    rgb_means.astype(np.float32),\n",
    "    object_posquats=initial_object_pose_in_camera_frame.posquat[None, ...].astype(np.float32),\n",
    "    log_spatial_scales=np.log(0.0005 * np.ones((spatial_means.shape[0], 3), dtype=np.float32))\n",
    ")\n",
    "print(gmm.object_posquats.numpy()[0])\n",
    "\n",
    "\n",
    "num_vertices = gmm.spatial_means.shape[0]\n",
    "pose_hypotheses = wp.empty(num_poses, dtype=wp.transform)\n",
    "pixel_coordinates = wp.zeros((num_poses, num_vertices), dtype=wp.vec2i)\n",
    "corresponding_rgbd_per_pose_and_vertex = wp.empty(\n",
    "    (num_poses, num_vertices), dtype=wp.vec4\n",
    ")\n",
    "scores_per_pose_and_vertex = wp.empty((num_poses, num_vertices), dtype=float)\n",
    "scores_per_pose = wp.zeros(num_poses, dtype=float)\n",
    "\n",
    "\n",
    "T = 0\n",
    "condorgmm.rr_set_time(T)\n",
    "condorgmm.rr_log_frame(video[T])\n",
    "warp_gmm.rr_log_gmm_warp(gmm, \"gmm_warp\", size_scalar=1.5)\n",
    "condorgmm.rr_log_pose(condorgmm.Pose(frame.camera_pose).inv() @ condorgmm.Pose(frame.object_poses[object_index]), \"gt_pose\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module condorgmm.warp_gmm.enumeration_kernels 0c9b6a8 load on device 'cuda:0' took 0.62 ms  (cached)\n",
      "[ 0.05233599 -0.0130313   0.8615899   0.0024441   0.69188577  0.26218858\n",
      " -0.6727148 ]\n",
      "[ 0.05947617 -0.0148075   0.85370094  0.01354977  0.7096188   0.22939762\n",
      " -0.6660587 ]\n",
      "[ 0.0822545  -0.01263825  0.86141527  0.01214595  0.71618855  0.22575256\n",
      " -0.66027415]\n",
      "[ 0.12117092 -0.05650976  0.8675858  -0.00810349  0.67433     0.24813344\n",
      " -0.6954444 ]\n",
      "[ 0.15147673 -0.03209625  0.8722536  -0.02203601  0.6450719   0.24393643\n",
      " -0.7238035 ]\n",
      "[ 0.12623484 -0.01215548  0.8902563  -0.01633698  0.6442113   0.23155552\n",
      " -0.72877085]\n",
      "[ 0.09787653 -0.00536741  0.9058726  -0.0149751   0.6563901   0.22773404\n",
      " -0.7190724 ]\n",
      "[ 0.10354301 -0.00155372  0.9089102  -0.01543457  0.62037855  0.23615047\n",
      " -0.74774677]\n",
      "[ 0.09856848 -0.00557951  0.91248703 -0.02945836  0.63146317  0.24518913\n",
      " -0.7350299 ]\n",
      "[ 0.08783374  0.00138029  0.9152598  -0.00177905  0.62677664  0.22979517\n",
      " -0.74454165]\n",
      "[ 0.09440718 -0.00562259  0.9146112  -0.00685717  0.6318138   0.2128432\n",
      " -0.74529326]\n",
      "[ 0.08111025 -0.00567861  0.917257   -0.00995271  0.6134275   0.20953108\n",
      " -0.76138324]\n",
      "[ 0.08113704 -0.0160734   0.9130151  -0.03834711  0.60922855  0.21784264\n",
      " -0.7615212 ]\n",
      "[ 9.3621083e-02 -8.0592744e-04  9.0957367e-01 -2.9236764e-02\n",
      "  5.9778488e-01  2.0733492e-01 -7.7382851e-01]\n",
      "[ 0.08766321  0.00158006  0.9164228  -0.04528787  0.604399    0.20024697\n",
      " -0.76977396]\n",
      "[ 0.12577297  0.01990574  0.91998464 -0.02064205  0.5810944   0.17937867\n",
      " -0.7935532 ]\n",
      "[ 0.13235036 -0.00934405  0.9322034  -0.02487967  0.5741733   0.17372678\n",
      " -0.7997031 ]\n",
      "[ 0.12394425  0.00176135  0.9430149  -0.0300775   0.55886006  0.17839156\n",
      " -0.80928797]\n",
      "[ 0.12081204  0.03757875  0.95346946 -0.02106992  0.54945385  0.17374112\n",
      " -0.8169886 ]\n",
      "[ 0.12284254  0.03610528  0.9767402  -0.02440808  0.5490811   0.17634763\n",
      " -0.8165876 ]\n",
      "[ 0.09862775  0.0057039   0.95626074 -0.02479042  0.5509861   0.19755004\n",
      " -0.81041557]\n",
      "[ 0.15795353  0.00824862  0.93903357 -0.02187128  0.51492685  0.17682394\n",
      " -0.83851355]\n",
      "[ 1.3450243e-01  2.6211739e-02  9.8477644e-01  7.5625896e-04\n",
      "  4.9771950e-01  1.7016646e-01 -8.5048103e-01]\n",
      "[ 0.14124703  0.01591152  1.0205919  -0.0123587   0.510176    0.17603673\n",
      " -0.8417712 ]\n",
      "[ 0.16403505  0.0168944   1.0144975  -0.01392301  0.51807535  0.17122598\n",
      " -0.8379055 ]\n",
      "[ 0.20194651  0.00645846  0.95567316 -0.02476192  0.48378098  0.18058711\n",
      " -0.85599697]\n",
      "[ 0.18691623 -0.01819964  0.9206228  -0.06484231  0.4769014   0.19156715\n",
      " -0.85537255]\n",
      "[ 0.16712454 -0.01035914  0.89370114 -0.04271677  0.4535847   0.18948768\n",
      " -0.86978745]\n",
      "[ 2.0387642e-01  4.6817377e-02  9.0498233e-01  5.2069395e-04\n",
      "  4.6403879e-01  1.6908720e-01 -8.6952686e-01]\n",
      "[ 0.16940485  0.02934947  0.93634135 -0.01267109  0.46665588  0.17177053\n",
      " -0.8675059 ]\n",
      "[ 0.13446759  0.03894972  0.9494639  -0.05490813  0.46573412  0.13575643\n",
      " -0.8727239 ]\n",
      "[ 0.12970518  0.0560673   0.9583191  -0.05261435  0.4447724   0.119964\n",
      " -0.88601226]\n",
      "[ 0.13620849  0.0965701   0.9663425  -0.02927349  0.45567402  0.10340592\n",
      " -0.88363534]\n",
      "[ 0.13558601  0.07435331  0.9588588  -0.01710173  0.44929838  0.10678577\n",
      " -0.88681185]\n",
      "[ 0.12035152  0.05333479  0.94973576 -0.00757979  0.44321334  0.12209082\n",
      " -0.8880306 ]\n",
      "[ 0.12661847  0.04132306  0.9297687   0.00353552  0.4149104   0.12401499\n",
      " -0.90136415]\n",
      "[ 0.12586123  0.02683727  0.9018739   0.01129171  0.4002194   0.1373997\n",
      " -0.9059903 ]\n",
      "[ 0.09449743  0.02211664  0.8879549   0.01120929  0.40648985  0.1398487\n",
      " -0.90281934]\n",
      "[ 0.10751668  0.015882    0.85453755  0.0031664   0.39491278  0.14914908\n",
      " -0.9065255 ]\n",
      "[ 0.11378212  0.0147884   0.8258474   0.00874751  0.37620685  0.14315033\n",
      " -0.9153687 ]\n",
      "[ 0.10826629  0.03056073  0.80846506  0.03297329  0.37439585  0.13297367\n",
      " -0.91709226]\n",
      "[ 0.10343624  0.02320985  0.7819637   0.03289808  0.37026632  0.12901144\n",
      " -0.9193347 ]\n",
      "[ 0.09672552  0.00976063  0.7562644   0.02402373  0.35603788  0.13063782\n",
      " -0.9249827 ]\n",
      "[ 0.09574503  0.01168685  0.7323939   0.02627437  0.3363986   0.13799691\n",
      " -0.93118316]\n",
      "[ 0.11164262  0.0101508   0.7060808   0.03797633  0.30966055  0.13465783\n",
      " -0.94049716]\n"
     ]
    }
   ],
   "source": [
    "inferred_object_poses = []\n",
    "for T in timesteps:\n",
    "    frame = video[T]\n",
    "    frame_warp = frame.as_warp()\n",
    "    \n",
    "    for pose_deltas in c2f_schedule:\n",
    "        inference_step(\n",
    "            gmm.object_posquats,\n",
    "            pose_deltas,\n",
    "            gmm.spatial_means,\n",
    "            gmm.rgb_means,\n",
    "            frame.intrinsics[0],\n",
    "            frame.intrinsics[1],\n",
    "            frame.intrinsics[2],\n",
    "            frame.intrinsics[3],\n",
    "            frame_warp.rgb,\n",
    "            frame_warp.depth,\n",
    "            # These inputs are empty memory that will be filled by the kernels.\n",
    "            pose_hypotheses,\n",
    "            pixel_coordinates,\n",
    "            corresponding_rgbd_per_pose_and_vertex,\n",
    "            scores_per_pose_and_vertex,\n",
    "            scores_per_pose,\n",
    "        )\n",
    "\n",
    "    object_pose = condorgmm.Pose(gmm.object_posquats.numpy()[0])\n",
    "    transformed_points = object_pose.apply(gmm.spatial_means.numpy())\n",
    "    proj_pixel_coords = (transformed_points[:, :2] / transformed_points[:, 2:3]) * np.array([frame.intrinsics[0], frame.intrinsics[1]]) + np.array([frame.intrinsics[2], frame.intrinsics[3]])\n",
    "    rounded_pixel_coordinates = np.floor(proj_pixel_coords).astype(np.int32)\n",
    "    valid = (rounded_pixel_coordinates[:, 0] >= 0) & (rounded_pixel_coordinates[:, 0] < frame.rgb.shape[1]) & (rounded_pixel_coordinates[:, 1] >= 0) & (rounded_pixel_coordinates[:, 1] < frame.rgb.shape[0])\n",
    "    rounded_pixel_coordinates = rounded_pixel_coordinates * valid[:, None]\n",
    "    associated_rgb = frame.rgb[rounded_pixel_coordinates[:, 1], rounded_pixel_coordinates[:, 0]]\n",
    "    associated_depth = frame.depth[rounded_pixel_coordinates[:, 1], rounded_pixel_coordinates[:, 0]]\n",
    "    matching = np.abs(associated_depth - transformed_points[:, 2]) < 0.005\n",
    "    matching_and_valid = matching & valid\n",
    "    rgb_means = gmm.rgb_means.numpy()\n",
    "    rgb_means[matching_and_valid,:] = associated_rgb[matching_and_valid,:]        \n",
    "    gmm.rgb_means = wp.array(rgb_means, dtype=wp.vec3)\n",
    "    \n",
    "        \n",
    "    print(gmm.object_posquats.numpy()[0])\n",
    "    condorgmm.rr_set_time(T)\n",
    "    warp_gmm.rr_log_gmm_warp(gmm, \"gmm_warp\", size_scalar=1.5)\n",
    "    condorgmm.rr_log_pose(gmm.object_posquats.numpy()[0], \"inferred_pose\")\n",
    "    inferred_object_poses.append(gmm.object_posquats.numpy()[0])\n",
    "    condorgmm.rr_log_pose(condorgmm.Pose(frame.camera_pose).inv() @ condorgmm.Pose(frame.object_poses[object_index]), \"gt_pose\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "051_large_clamp\n"
     ]
    }
   ],
   "source": [
    "object_id = video[0].object_ids[object_index]\n",
    "object_mesh = video.get_object_mesh_from_id(object_id)\n",
    "object_name = video.get_object_name_from_id(object_id)\n",
    "print(object_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = condorgmm.eval.metrics.create_empty_results_dataframe()\n",
    "condorgmm.eval.metrics.add_object_tracking_metrics_to_results_dataframe(\n",
    "    results_df,\n",
    "    scene,\n",
    "    \"condorgmm\",\n",
    "    object_name,\n",
    "    predicted_poses,\n",
    "    gt_poses,\n",
    "    vertices,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import condorgmm.eval.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import condorgmm.eval.fp_loader\n",
    "fp_loader = condorgmm.eval.fp_loader.YCBVTrackingResultLoader(\n",
    "    frame_rate=50, split=ycb_dir.name\n",
    ")\n",
    "fp_df = fp_loader.get_dataframe(scene)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_poses = [\n",
    "    condorgmm.Pose(video[t].camera_pose).inv()\n",
    "    @ condorgmm.Pose(video[t].object_poses[current_object_index])\n",
    "    for t in timesteps\n",
    "]\n",
    "\n",
    "vertices = video.get_object_mesh_from_id(\n",
    "    video[0].object_ids[current_object_index]\n",
    ").vertices\n",
    "\n",
    "inferred_object_poses = [condorgmm.Pose(pose) for pose in inferred_object_poses]\n",
    "\n",
    "results_df = condorgmm.eval.metrics.create_empty_results_dataframe()\n",
    "condorgmm.eval.metrics.add_object_tracking_metrics_to_results_dataframe(\n",
    "    results_df,\n",
    "    scene,\n",
    "    \"condorgmm\",\n",
    "    object_name,\n",
    "    inferred_object_poses,\n",
    "    gt_poses,\n",
    "    vertices,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric  method          object               \n",
      "ADD     FoundationPose  002_master_chef_can      0.204111\n",
      "                        007_tuna_fish_can        0.571778\n",
      "                        025_mug                  0.650444\n",
      "                        051_large_clamp          0.441000\n",
      "                        052_extra_large_clamp    0.325000\n",
      "        condorgmm           051_large_clamp          0.914556\n",
      "ADD-S   FoundationPose  002_master_chef_can      0.629667\n",
      "                        007_tuna_fish_can        0.816111\n",
      "                        025_mug                  0.826111\n",
      "                        051_large_clamp          0.547000\n",
      "                        052_extra_large_clamp    0.979000\n",
      "        condorgmm           051_large_clamp          0.964556\n",
      "Name: value, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "full_df = pd.concat([fp_df, results_df])\n",
    "auc_results_full = full_df.groupby([\"metric\", \"method\", \"object\"])[\"value\"].apply(\n",
    "    condorgmm.eval.metrics.compute_auc\n",
    ")\n",
    "print(auc_results_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scene</th>\n",
       "      <th>method</th>\n",
       "      <th>object</th>\n",
       "      <th>timestep</th>\n",
       "      <th>predicted</th>\n",
       "      <th>gt</th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48</td>\n",
       "      <td>FoundationPose</td>\n",
       "      <td>002_master_chef_can</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.03245632350444794, -0.008746874518692493, ...</td>\n",
       "      <td>[-0.031677025422232274, -0.017368816807616497,...</td>\n",
       "      <td>ADD-S</td>\n",
       "      <td>0.006057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>FoundationPose</td>\n",
       "      <td>002_master_chef_can</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.024065330624580383, -0.014229506254196167,...</td>\n",
       "      <td>[-0.023487833882362825, -0.02297177083569611, ...</td>\n",
       "      <td>ADD-S</td>\n",
       "      <td>0.006084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48</td>\n",
       "      <td>FoundationPose</td>\n",
       "      <td>002_master_chef_can</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0015329779125750065, -0.012915787287056446,...</td>\n",
       "      <td>[0.0007751038657471028, -0.02009170430772513, ...</td>\n",
       "      <td>ADD-S</td>\n",
       "      <td>0.005083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>FoundationPose</td>\n",
       "      <td>002_master_chef_can</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.02247895672917366, -0.02795446291565895, 0....</td>\n",
       "      <td>[0.03918443426687707, -0.06518133103855758, 0....</td>\n",
       "      <td>ADD-S</td>\n",
       "      <td>0.031214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48</td>\n",
       "      <td>FoundationPose</td>\n",
       "      <td>002_master_chef_can</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.029076755046844482, -0.0484016053378582, 0....</td>\n",
       "      <td>[0.07212755206100327, -0.044044601048402854, 0...</td>\n",
       "      <td>ADD-S</td>\n",
       "      <td>0.044196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>48</td>\n",
       "      <td>FoundationPose</td>\n",
       "      <td>052_extra_large_clamp</td>\n",
       "      <td>40</td>\n",
       "      <td>[-0.12645815312862396, 0.0952477902173996, 0.8...</td>\n",
       "      <td>[-0.10260229912475038, 0.0939881687277426, 0.8...</td>\n",
       "      <td>ADD</td>\n",
       "      <td>0.067866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>48</td>\n",
       "      <td>FoundationPose</td>\n",
       "      <td>052_extra_large_clamp</td>\n",
       "      <td>41</td>\n",
       "      <td>[-0.13152475655078888, 0.08612556755542755, 0....</td>\n",
       "      <td>[-0.10976216625644014, 0.0858998113975631, 0.7...</td>\n",
       "      <td>ADD</td>\n",
       "      <td>0.067433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>48</td>\n",
       "      <td>FoundationPose</td>\n",
       "      <td>052_extra_large_clamp</td>\n",
       "      <td>42</td>\n",
       "      <td>[-0.1385863721370697, 0.07273939996957779, 0.7...</td>\n",
       "      <td>[-0.11486511993147, 0.07214020082416844, 0.768...</td>\n",
       "      <td>ADD</td>\n",
       "      <td>0.067781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>48</td>\n",
       "      <td>FoundationPose</td>\n",
       "      <td>052_extra_large_clamp</td>\n",
       "      <td>43</td>\n",
       "      <td>[-0.13955964148044586, 0.07709338515996933, 0....</td>\n",
       "      <td>[-0.11537487219915202, 0.07519616048985027, 0....</td>\n",
       "      <td>ADD</td>\n",
       "      <td>0.067805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>48</td>\n",
       "      <td>FoundationPose</td>\n",
       "      <td>052_extra_large_clamp</td>\n",
       "      <td>44</td>\n",
       "      <td>[-0.12293644994497299, 0.07664990425109863, 0....</td>\n",
       "      <td>[-0.0984797407149884, 0.07571833345621048, 0.7...</td>\n",
       "      <td>ADD</td>\n",
       "      <td>0.067827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>450 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    scene          method                 object  timestep  \\\n",
       "0      48  FoundationPose    002_master_chef_can         0   \n",
       "1      48  FoundationPose    002_master_chef_can         1   \n",
       "2      48  FoundationPose    002_master_chef_can         2   \n",
       "3      48  FoundationPose    002_master_chef_can         3   \n",
       "4      48  FoundationPose    002_master_chef_can         4   \n",
       "..    ...             ...                    ...       ...   \n",
       "40     48  FoundationPose  052_extra_large_clamp        40   \n",
       "41     48  FoundationPose  052_extra_large_clamp        41   \n",
       "42     48  FoundationPose  052_extra_large_clamp        42   \n",
       "43     48  FoundationPose  052_extra_large_clamp        43   \n",
       "44     48  FoundationPose  052_extra_large_clamp        44   \n",
       "\n",
       "                                            predicted  \\\n",
       "0   [-0.03245632350444794, -0.008746874518692493, ...   \n",
       "1   [-0.024065330624580383, -0.014229506254196167,...   \n",
       "2   [0.0015329779125750065, -0.012915787287056446,...   \n",
       "3   [0.02247895672917366, -0.02795446291565895, 0....   \n",
       "4   [0.029076755046844482, -0.0484016053378582, 0....   \n",
       "..                                                ...   \n",
       "40  [-0.12645815312862396, 0.0952477902173996, 0.8...   \n",
       "41  [-0.13152475655078888, 0.08612556755542755, 0....   \n",
       "42  [-0.1385863721370697, 0.07273939996957779, 0.7...   \n",
       "43  [-0.13955964148044586, 0.07709338515996933, 0....   \n",
       "44  [-0.12293644994497299, 0.07664990425109863, 0....   \n",
       "\n",
       "                                                   gt metric     value  \n",
       "0   [-0.031677025422232274, -0.017368816807616497,...  ADD-S  0.006057  \n",
       "1   [-0.023487833882362825, -0.02297177083569611, ...  ADD-S  0.006084  \n",
       "2   [0.0007751038657471028, -0.02009170430772513, ...  ADD-S  0.005083  \n",
       "3   [0.03918443426687707, -0.06518133103855758, 0....  ADD-S  0.031214  \n",
       "4   [0.07212755206100327, -0.044044601048402854, 0...  ADD-S  0.044196  \n",
       "..                                                ...    ...       ...  \n",
       "40  [-0.10260229912475038, 0.0939881687277426, 0.8...    ADD  0.067866  \n",
       "41  [-0.10976216625644014, 0.0858998113975631, 0.7...    ADD  0.067433  \n",
       "42  [-0.11486511993147, 0.07214020082416844, 0.768...    ADD  0.067781  \n",
       "43  [-0.11537487219915202, 0.07519616048985027, 0....    ADD  0.067805  \n",
       "44  [-0.0984797407149884, 0.07571833345621048, 0.7...    ADD  0.067827  \n",
       "\n",
       "[450 rows x 8 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "corresponding_rgbd_per_pose_and_vertex_np = corresponding_rgbd_per_pose_and_vertex.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.   ,  0.   , 22.   ,  0.832], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corresponding_rgbd_per_pose_and_vertex_np[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-9993.419, -9993.419, -9993.419, ..., -9993.419, -9993.419,\n",
       "       -9993.419], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_per_pose.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
