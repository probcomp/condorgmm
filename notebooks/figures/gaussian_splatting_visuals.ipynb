{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import condorgmm\n",
    "import torch\n",
    "import gsplat\n",
    "from condorgmm.ng.torch_utils import render_rgbd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "condorgmm.rr_init(\"coarse_models_sweep\")\n",
    "\n",
    "video = condorgmm.data.YCBTestVideo(48)\n",
    "frame0 = video[0]\n",
    "\n",
    "fx, fy, cx, cy = frame0.intrinsics\n",
    "height, width = frame0.depth.shape\n",
    "\n",
    "viewmat = torch.tensor(\n",
    "    [\n",
    "        [1.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 1.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 1.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 1.0],\n",
    "    ],\n",
    "    device=device,\n",
    "    dtype=torch.float32,\n",
    ")\n",
    "K = torch.tensor(\n",
    "    [\n",
    "        [frame0.fx, 0, frame0.width / 2],\n",
    "        [0, frame0.fy, frame0.height / 2],\n",
    "        [0, 0, 1],\n",
    "    ],\n",
    "    device=device,\n",
    "    dtype=torch.float32,\n",
    ")\n",
    "\n",
    "object_mask = np.full(frame0.depth.shape, True)\n",
    "\n",
    "camera_posquat = torch.tensor([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], device=device, requires_grad=True)\n",
    "posquat = torch.tensor([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], device=device, requires_grad=True)\n",
    "means = torch.tensor([[0.0, 0.0, 1.0]], device=device, requires_grad=True)\n",
    "quats = torch.tensor([[0.0, 0.0, 0.0, 1.0]], device=device, requires_grad=True)\n",
    "scales = torch.tensor([[0.01, 0.01, 0.01]], device=device, requires_grad=True)\n",
    "opacities = torch.tensor([1.0], device=device, requires_grad=True)\n",
    "rgbs = torch.tensor([[1.0, 0.0, 0.0]], device=device, requires_grad=True)\n",
    "\n",
    "rendered_rgb, rendered_depth, rendered_silhouette = render_rgbd(\n",
    "    camera_posquat,\n",
    "    posquat,\n",
    "    means,\n",
    "    quats,\n",
    "    torch.exp(scales),\n",
    "    torch.sigmoid(opacities),\n",
    "    rgbs,\n",
    "    viewmat[None],\n",
    "    K[None],\n",
    "    frame0.width,\n",
    "    frame0.height,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'gsplat_cuda' has no attribute 'projection_ewa_3dgs_fused_fwd'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m opacities = torch.tensor([\u001b[32m1.0\u001b[39m], device=device, requires_grad=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      7\u001b[39m rgbs = torch.tensor([[\u001b[32m1.0\u001b[39m, \u001b[32m0.0\u001b[39m, \u001b[32m0.0\u001b[39m]], device=device, requires_grad=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m rendered_rgb, rendered_depth, rendered_silhouette = \u001b[43mrender_rgbd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcamera_posquat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposquat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmeans\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscales\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43msigmoid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopacities\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrgbs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mviewmat\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mK\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mframe0\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mframe0\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/condorgmm/src/condorgmm/ng/torch_utils.py:58\u001b[39m, in \u001b[36mrender_rgbd\u001b[39m\u001b[34m(camera_posquat, posquat, means, quats, scales, opacities, rgbs, viewmat, K, width, height)\u001b[39m\n\u001b[32m     55\u001b[39m means = transform_points(means, posquat_transform)\n\u001b[32m     56\u001b[39m means = transform_points(means, camera_posquat_transform_inv)\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m rgb = \u001b[43mrasterization\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmeans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscales\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopacities\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrgbs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mviewmat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpacked\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m     60\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m]\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# Get depth\u001b[39;00m\n\u001b[32m     63\u001b[39m colors_but_actually_depths = torch.zeros_like(rgbs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/condorgmm/.pixi/envs/default/lib/python3.12/site-packages/gsplat/rendering.py:297\u001b[39m, in \u001b[36mrasterization\u001b[39m\u001b[34m(means, quats, scales, opacities, colors, viewmats, Ks, width, height, near_plane, far_plane, radius_clip, eps2d, sh_degree, packed, tile_size, backgrounds, render_mode, sparse_grad, absgrad, rasterize_mode, channel_chunk, distributed, camera_model, covars)\u001b[39m\n\u001b[32m    294\u001b[39m     C = \u001b[38;5;28mlen\u001b[39m(viewmats)\n\u001b[32m    296\u001b[39m \u001b[38;5;66;03m# Project Gaussians to 2D. Directly pass in {quats, scales} is faster than precomputing covars.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m297\u001b[39m proj_results = \u001b[43mfully_fused_projection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmeans\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcovars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    301\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscales\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    302\u001b[39m \u001b[43m    \u001b[49m\u001b[43mviewmats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    303\u001b[39m \u001b[43m    \u001b[49m\u001b[43mKs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    304\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    305\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    306\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps2d\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    307\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpacked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpacked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    308\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnear_plane\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnear_plane\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfar_plane\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfar_plane\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[43m    \u001b[49m\u001b[43mradius_clip\u001b[49m\u001b[43m=\u001b[49m\u001b[43mradius_clip\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m    \u001b[49m\u001b[43msparse_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[43msparse_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcalc_compensations\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrasterize_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mantialiased\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcamera_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcamera_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m    \u001b[49m\u001b[43mopacities\u001b[49m\u001b[43m=\u001b[49m\u001b[43mopacities\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# use opacities to compute a tigher bound for radii.\u001b[39;49;00m\n\u001b[32m    315\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m packed:\n\u001b[32m    318\u001b[39m     \u001b[38;5;66;03m# The results are packed into shape [nnz, ...]. All elements are valid.\u001b[39;00m\n\u001b[32m    319\u001b[39m     (\n\u001b[32m    320\u001b[39m         camera_ids,\n\u001b[32m    321\u001b[39m         gaussian_ids,\n\u001b[32m   (...)\u001b[39m\u001b[32m    326\u001b[39m         compensations,\n\u001b[32m    327\u001b[39m     ) = proj_results\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/condorgmm/.pixi/envs/default/lib/python3.12/site-packages/gsplat/cuda/_wrapper.py:337\u001b[39m, in \u001b[36mfully_fused_projection\u001b[39m\u001b[34m(means, covars, quats, scales, viewmats, Ks, width, height, eps2d, near_plane, far_plane, radius_clip, packed, sparse_grad, calc_compensations, camera_model, opacities)\u001b[39m\n\u001b[32m    318\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _FullyFusedProjectionPacked.apply(\n\u001b[32m    319\u001b[39m         means,\n\u001b[32m    320\u001b[39m         covars,\n\u001b[32m   (...)\u001b[39m\u001b[32m    334\u001b[39m         opacities,\n\u001b[32m    335\u001b[39m     )\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_FullyFusedProjection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    338\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmeans\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    339\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcovars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    340\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscales\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[43m        \u001b[49m\u001b[43mviewmats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    343\u001b[39m \u001b[43m        \u001b[49m\u001b[43mKs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    344\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    345\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    346\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnear_plane\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfar_plane\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m        \u001b[49m\u001b[43mradius_clip\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcalc_compensations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcamera_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m        \u001b[49m\u001b[43mopacities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/condorgmm/.pixi/envs/default/lib/python3.12/site-packages/torch/autograd/function.py:575\u001b[39m, in \u001b[36mFunction.apply\u001b[39m\u001b[34m(cls, *args, **kwargs)\u001b[39m\n\u001b[32m    572\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch._C._are_functorch_transforms_active():\n\u001b[32m    573\u001b[39m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[32m    574\u001b[39m     args = _functorch.utils.unwrap_dead_wrappers(args)\n\u001b[32m--> \u001b[39m\u001b[32m575\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m    577\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[32m    578\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    579\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    580\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    581\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mstaticmethod. For more details, please see \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    582\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    583\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/condorgmm/.pixi/envs/default/lib/python3.12/site-packages/gsplat/cuda/_wrapper.py:777\u001b[39m, in \u001b[36m_FullyFusedProjection.forward\u001b[39m\u001b[34m(ctx, means, covars, quats, scales, viewmats, Ks, width, height, eps2d, near_plane, far_plane, radius_clip, calc_compensations, camera_model, opacities)\u001b[39m\n\u001b[32m    772\u001b[39m camera_model_type = _make_lazy_cuda_obj(\n\u001b[32m    773\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCameraModelType.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcamera_model.upper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    774\u001b[39m )\n\u001b[32m    776\u001b[39m \u001b[38;5;66;03m# \"covars\" and {\"quats\", \"scales\"} are mutually exclusive\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m777\u001b[39m radii, means2d, depths, conics, compensations = \u001b[43m_make_lazy_cuda_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    778\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprojection_ewa_3dgs_fused_fwd\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    779\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    780\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmeans\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    781\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcovars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    782\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    783\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscales\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    784\u001b[39m \u001b[43m    \u001b[49m\u001b[43mopacities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    785\u001b[39m \u001b[43m    \u001b[49m\u001b[43mviewmats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    786\u001b[39m \u001b[43m    \u001b[49m\u001b[43mKs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    787\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnear_plane\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfar_plane\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mradius_clip\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcalc_compensations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcamera_model_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m calc_compensations:\n\u001b[32m    797\u001b[39m     compensations = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/condorgmm/.pixi/envs/default/lib/python3.12/site-packages/gsplat/cuda/_wrapper.py:14\u001b[39m, in \u001b[36m_make_lazy_cuda_func.<locals>.call_cuda\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_cuda\u001b[39m(*args, **kwargs):\n\u001b[32m     11\u001b[39m     \u001b[38;5;66;03m# pylint: disable=import-outside-toplevel\u001b[39;00m\n\u001b[32m     12\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_backend\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _C\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m(*args, **kwargs)\n",
      "\u001b[31mAttributeError\u001b[39m: module 'gsplat_cuda' has no attribute 'projection_ewa_3dgs_fused_fwd'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Running for {num_gaussians} Gaussians\")\n",
    "sampled_indices = np.random.choice(\n",
    "    object_mask.sum(), num_gaussians, replace=False\n",
    ")\n",
    "\n",
    "rgb_means_np = frame0.rgb[object_mask][sampled_indices].astype(np.float32)\n",
    "spatial_means_np = condorgmm.utils.common.xyz_from_depth_image(\n",
    "    frame0.depth, fx, fy, cx, cy\n",
    ")[object_mask][sampled_indices].astype(np.float32)\n",
    "\n",
    "rgb_means_np = frame0.rgb[object_mask][sampled_indices].astype(np.float32)\n",
    "spatial_means_np = condorgmm.utils.common.xyz_from_depth_image(\n",
    "    frame0.depth, fx, fy, cx, cy\n",
    ")[object_mask][sampled_indices].astype(np.float32)\n",
    "# Subsample the points\n",
    "\n",
    "means = torch.tensor(\n",
    "    spatial_means_np, device=device, requires_grad=True, dtype=torch.float32\n",
    ")\n",
    "rgbs = torch.tensor(\n",
    "    rgb_means_np, device=device, requires_grad=True, dtype=torch.float32\n",
    ")\n",
    "\n",
    "quats = torch.randn(num_gaussians, 4, device=device, requires_grad=True)\n",
    "quats = torch.tensor(\n",
    "    np.tile(np.array([0.0, 0.0, 0.0, 1.0]), (num_gaussians, 1)),\n",
    "    device=device,\n",
    "    requires_grad=True,\n",
    "    dtype=torch.float32,\n",
    ")\n",
    "scales = torch.tensor(\n",
    "    torch.log(torch.randn(num_gaussians, 3) * 0.01),\n",
    "    device=device,\n",
    "    requires_grad=True,\n",
    "    dtype=torch.float32,\n",
    ")\n",
    "opacities = torch.tensor(\n",
    "    np.ones(num_gaussians) * 4.0,\n",
    "    device=device,\n",
    "    requires_grad=True,\n",
    "    dtype=torch.float32,\n",
    ")\n",
    "\n",
    "# Get target image\n",
    "target_img = torch.tensor(frame0.rgb, device=device).float()\n",
    "target_depth = torch.tensor(frame0.depth, device=device).float()\n",
    "\n",
    "object_mask_torch = torch.tensor(object_mask, device=device).float()\n",
    "# object_mask = torch.tensor(frame0.masks[object_index], device=device).float()\n",
    "\n",
    "scales.requires_grad_ = True\n",
    "opacities.requires_grad_ = True\n",
    "\n",
    "posquat = torch.tensor(\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], device=device, requires_grad=True\n",
    ")\n",
    "camera_posquat = torch.tensor(\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], device=device, requires_grad=True\n",
    ")\n",
    "\n",
    "# Setup optimizer\n",
    "optimizer = torch.optim.Adam([means, rgbs, opacities, scales], lr=2e-3)\n",
    "n_steps = 1500\n",
    "pbar = tqdm(range(n_steps))\n",
    "for step in pbar:\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    rendered_rgb, rendered_depth, rendered_silhouette = render_rgbd(\n",
    "        camera_posquat,\n",
    "        posquat,\n",
    "        means,\n",
    "        quats,\n",
    "        torch.exp(scales),\n",
    "        torch.sigmoid(opacities),\n",
    "        rgbs,\n",
    "        viewmat[None],\n",
    "        K[None],\n",
    "        frame0.width,\n",
    "        frame0.height,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
