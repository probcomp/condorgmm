{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starter notebook for analyzing inference behavior\n",
    "\n",
    "This notebook is intended to be a template to start from for analyzing inference behavior.\n",
    "If you push changes to this notebook, they are changes to the starter template!\n",
    "\n",
    "When working on studying inferenve behavior, please make a copy of this notebook in a folder\n",
    "with your name on it.  (E.g. George would make a copy of this notebook in `notebooks/gm`.)\n",
    "Then feel free to modify that notebook as you please in your debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import condorgmm\n",
    "import condorgmm.model\n",
    "import genjax\n",
    "import condorgmm.end_to_end\n",
    "from condorgmm.config.default import configuration as config\n",
    "from tqdm import tqdm\n",
    "from condorgmm.utils import inference_analysis_utils as iau\n",
    "import matplotlib.pyplot as plt\n",
    "genjax.pretty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_id = 1\n",
    "OBJECT_INDEX = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load video & object\n",
    "FRAME_RATE = 50\n",
    "ycb_dir = condorgmm.get_root_path() / \"assets/bop/ycbv/train_real\"\n",
    "\n",
    "all_data, meshes, intrinsics = condorgmm.load_scene(ycb_dir, scene_id, FRAME_RATE)\n",
    "initial_object_poses = (\n",
    "    all_data[0][\"camera_pose\"].inv() @ all_data[0][\"object_poses\"]\n",
    ")\n",
    "def gt_pose(T):\n",
    "    return all_data[T][\"camera_pose\"].inv() @ all_data[T][\"object_poses\"][OBJECT_INDEX]\n",
    "\n",
    "# Get initial state\n",
    "initial_state, vertices = condorgmm.end_to_end.get_initial_state_for_object(\n",
    "    meshes, OBJECT_INDEX, initial_object_poses\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize rerun\n",
    "rr_name = f\"result_analysis_sc{scene_id}_obj{OBJECT_INDEX}\"\n",
    "condorgmm.rr_init(rr_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate trace at initial pose with derministically initialized state\n",
    "key = jax.random.PRNGKey(0)\n",
    "trace = condorgmm.end_to_end.initialize_inference(\n",
    "    initial_state, all_data, config.model_hyperparams_first_frame, vertices, intrinsics\n",
    ")\n",
    "condorgmm.model.viz_trace(\n",
    "    trace,\n",
    "    -1,\n",
    "    ground_truth_pose=gt_pose(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the point properties at this fixed pose, at T=0\n",
    "key, subkey = jax.random.split(key)\n",
    "trace, _, _ = (\n",
    "    condorgmm.inference.update_all_variables_given_pose(\n",
    "        key,\n",
    "        trace,\n",
    "        trace.get_choices()[\"pose\"],\n",
    "        config.point_attribute_proposal,\n",
    "    )\n",
    ")\n",
    "condorgmm.model.viz_trace(\n",
    "    trace,\n",
    "    0,\n",
    "    ground_truth_pose=gt_pose(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update hyperparams for subsequent frames\n",
    "trace_pre_loop = condorgmm.end_to_end.update_hyperparams_for_subsequent_frames(\n",
    "    trace, config.model_hyperparams_subsequent_frames\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference over the full video\n",
    "maxT = len(all_data)\n",
    "trace = trace_pre_loop\n",
    "trs = []\n",
    "keys = []\n",
    "for T in tqdm(range(1, maxT)):\n",
    "    trs.append(trace)\n",
    "    keys.append(key)\n",
    "    key, _ = jax.random.split(key)\n",
    "    trace = condorgmm.end_to_end.run_inference_step(\n",
    "        trace, gt_pose(T), True, config.point_attribute_proposal, all_data[T][\"rgbd\"],\n",
    "        key,\n",
    "        do_advance_time = True\n",
    "    )\n",
    "    condorgmm.model.viz_trace(\n",
    "        trace,\n",
    "        T,\n",
    "        ground_truth_pose=all_data[T][\"camera_pose\"].inv()\n",
    "        @ all_data[T][\"object_poses\"][OBJECT_INDEX],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Below here -- setup for inspecting specific frames with issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_bad = 13 # The frame to be inspected (a frame at which tracking got off)\n",
    "\n",
    "trace_pre_error = trs[T_bad - 1]\n",
    "key_pre_error = keys[T_bad - 1]\n",
    "\n",
    "# Reconstruct the first step of C2F at this frame where something went wrong.\n",
    "# Use the same PRNGKey as from the main loop above,\n",
    "# so this gives you the exact thing that happened internally\n",
    "# in the algorithm above.\n",
    "key_advanced, _ = jax.random.split(key_pre_error)\n",
    "tr_advanced = condorgmm.inference.advance_time(\n",
    "    key_advanced, trace_pre_error, all_data[T_bad][\"rgbd\"]\n",
    ")\n",
    "key_stp1 = jax.random.split(key_advanced)[-1]\n",
    "tr_stp1, metadata = condorgmm.inference.inference_step(\n",
    "    key_stp1,\n",
    "    tr_advanced,\n",
    "    0.04,\n",
    "    1500.0,\n",
    "    2000,\n",
    "    config.point_attribute_proposal,\n",
    "    use_gt_pose=True,\n",
    "    gt_pose=gt_pose(T_bad),\n",
    "    get_metadata=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Max log importance weight - log importance weight of trace at GT pose:\", jnp.max(metadata[\"scores\"]) - metadata[\"scores\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the 100 largest importance weights\n",
    "plt.plot(jnp.sort(metadata[\"scores\"])[::-1][0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regenerate the trace that was at the ground truth pose\n",
    "k = jax.random.split(metadata[\"key_for_point_proposals\"], 2000)[-1]\n",
    "gt_pose_tr, gt_pose_score, _ = condorgmm.inference.update_all_variables_given_pose(\n",
    "    k, tr_stp1, gt_pose(T_bad), config.point_attribute_proposal\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the preceding trace, the resampled trace at T_bad, and the trace at the\n",
    "# ground truth pose generated in the first step of C2F at T_bad.\n",
    "condorgmm.rr_init(f\"{rr_name}-T{T_bad}--1\")\n",
    "condorgmm.model.viz_trace(trace_pre_error, 0, ground_truth_pose=gt_pose(T_bad-1))\n",
    "condorgmm.model.viz_trace(tr_stp1, 1, ground_truth_pose=gt_pose(T_bad))\n",
    "condorgmm.model.viz_trace(gt_pose_tr, 10, ground_truth_pose=gt_pose(T_bad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick summary of some of the sub trace scores, and other differences between the traces:\n",
    "iau.print_trace_subscore_diffs(tr_stp1, gt_pose_tr)\n",
    "print(f\"Num visibility flag flips in resampled trace: {iau.get_n_visibility_flips(tr_stp1)}\")\n",
    "print(f\"Num visibility flag flips in gt pose trace: {iau.get_n_visibility_flips(gt_pose_tr)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Penzai inspection of the two traces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_pose_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_stp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the difference in the total proposal scores for all point-level\n",
    "# proposals in the two traces.  (This ignores Q score for pose proposals, but\n",
    "# that is usually small [magnitude <15].)\n",
    "d = metadata[\"point_proposal_metadata\"][\"proposal_scores\"]\n",
    "(d[metadata[\"sampled_index\"]].sum() - d[-1].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that you can also look at the `metadata` dict to see a lot more\n",
    "# details about the c2f step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condorgmm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
